######### Basic Settings #########
basic:
    device: '5'
    seed: [1993] # icarl 官方代码给的种子是 1993
    num_workers: 8

    # Dataset Choises: cifar100, cifar100, imagenet100, imagenet1000, tinyimagenet,
    # skin7, sd198(also known as skin40), mymedmnist
    dataset: cifar100
    shuffle: true

    # Method Choises: icarl, end2end, dr, ucir, bic, lwm, podnet, mas, joint， finetune
    method: multi_bn
    method_type: multi_steps
    # eval_metric Choises: acc, recall
    eval_metric: acc

    # Backbone Choises: resnet18, resnet18_cbam, cosine_resnet18, 
    # resnet32, cosine_resnet32, resnet34, cosine_resnet34, resnet50
    backbone: resnet18_cbam
    pretrained: true
    save_models: false # if true, programm will save model's weights during incremental train

    ######### Exampler Hyperparameters #########
    # memory_size: 2000
    # fixed_memory: false
    # sampling_method: herding # herding, random, closest_to_mean 

    ######### Task Settings, unimportant in Joint #########
    # for some datasets(e.g. MedMNist), this will be ignored
    split_dataset: true
    init_cls: 10
    increment: 10


######### Method's Hyperparameters #########
special:
    incre_type: til
    bn_type: default

######### Experiment Settings for Datasets #########
options:
    # experiment settings for cifar100
    cifar100: 
        resnet32:
            pretrain_path: pretrain_weights/imagenet200_simsiam_model_32.pth
            opt_type: adam
            init_epochs: 200 # 200
            init_lrate: 0.1
            init_scheduler: multi_step
            init_milestones: [60,120,160]
            init_lrate_decay: 0.1
            init_weight_decay: 0.0005

            epochs: 80 # 80
            lrate: 0.1
            scheduler: multi_step
            milestones: [40, 70]
            lrate_decay: 0.1
            batch_size: 128
            weight_decay: 0.0002
        
        resnet18_cbam:
            pretrain_path: pretrain_weights/imagenet200_simsiam_pretrained_model.pth
            opt_type: adam
            init_epochs: 200
            init_lrate: 0.1
            init_scheduler: multi_step
            init_milestones: [60,120,160]
            init_lrate_decay: 0.1
            init_weight_decay: 0.0005

            epochs: 80
            lrate: 0.1
            scheduler: multi_step
            milestones: [40, 70]
            lrate_decay: 0.1
            batch_size: 128
            weight_decay: 0.0002
    
    sd198: 
        resnet18:
            pretrain_path: pretrain_weights/sd198_simsiam_model_18_224.pth
            opt_type: sgd
            init_epochs: 200
            init_lrate: 0.01
            init_milestones: [100, 150]
            init_lrate_decay: 0.1
            init_weight_decay: 0.00001

            epochs: 200
            lrate: 0.01
            scheduler: multi_step
            milestones: [100, 150]
            lrate_decay: 0.1
            batch_size: 32
            weight_decay: 0.00001
    
    MedMinist:
        resnet18_cbam:
            pretrain_path: pretrain_weights/imagenet200_simsiam_pretrained_model.pth
            opt_type: adam
            init_epochs: 70
            init_lrate: 0.001
            init_scheduler: multi_step
            init_milestones: [49, 63]
            init_lrate_decay: 0.1
            init_weight_decay: 0.0002

            epochs: 70
            lrate: 0.001
            scheduler: multi_step
            milestones: [49, 63]
            lrate_decay: 0.1
            batch_size: 64
            weight_decay: 0.0002
            
