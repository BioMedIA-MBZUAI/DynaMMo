######### Basic Settings #########
basic:
    device: '0'
    seed: [50, 42] # 1, 50, 42, 100, 1993

    # Dataset Choises: cifar100, cifar100, imagenet100, imagenet1000, tinyimagenet,
    # skin7, sd198(also known as skin40), mymedmnist
    dataset: skin8
    shuffle: false

    # Method Choises: icarl, end2end, dr, ucir, bic, lwm, podnet, mas, jointï¼Œ finetune
    method: dynamic_er
    method_type: multi_steps
    # eval_metric Choises: acc, mcr
    eval_metric: mcr
    openset_test: true

    # Backbone Choises: resnet18
    backbone: efficientnet_b0
    pretrained: true # false
    save_models: true # if true, programm will save model's weights during incremental train

    ######### Exampler Hyperparameters #########
    memory_size: 40
    fixed_memory: false
    sampling_method: herding # herding, random, closest_to_mean

    ######### Task Settings, unimportant in Joint #########
    # for some datasets(e.g. MedMNist), this will be ignored
    split_dataset: true
    init_cls: 2
    increment: 2

    logger_type: tensorboard

    note: pretrain_buffer40_lr0.001_ft0.01

######### Method's Hyperparameters #########
special:
    incre_type: cil
    T: 5

######### Experiment Settings for Datasets #########
options:
    # experiment settings for cifar100
    skin8:        
        resnet18:
            img_size: 224
            opt_type: sgd
            epochs: 200 # 200
            lrate: 0.01
            scheduler: multi_step
            milestones: [100,120]
            lrate_decay: 0.1
            weight_decay: 0.0005
            batch_size: 32
            num_workers: 4

            epochs_finetune: 100 # 50
            lrate_finetune: 0.01
            milestones_finetune: [55, 80]
        
        mobilenet_v2:
            img_size: 224
            opt_type: sgd
            epochs: 200 # 200
            lrate: 0.001
            scheduler: multi_step
            milestones: [100,120]
            lrate_decay: 0.1
            weight_decay: 0.0005
            batch_size: 32
            num_workers: 4

            epochs_finetune: 100 # 100
            lrate_finetune: 0.01
            milestones_finetune: [55, 80]
        
        efficientnet_b0:
            img_size: 224
            opt_type: sgd
            epochs: 200 # 200
            lrate: 0.01
            scheduler: multi_step
            milestones: [100,120]
            lrate_decay: 0.1
            weight_decay: 0.0005
            batch_size: 32
            num_workers: 4

            epochs_finetune: 100 # 50
            lrate_finetune: 0.01
            milestones_finetune: [55, 80]