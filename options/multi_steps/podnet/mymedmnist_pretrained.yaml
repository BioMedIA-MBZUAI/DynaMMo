######### Basic Settings #########
basic:
    device: '3'
    seed: [1] # 42, 100, 1993

    # Dataset Choises: cifar100, cifar100, imagenet100, imagenet1000, tinyimagenet,
    # skin7, sd198(also known as skin40), mymedmnist
    dataset: mymedmnist
    shuffle: false

    # Method Choises: icarl, end2end, dr, ucir, bic, lwm, podnet, mas, jointï¼Œ finetune
    method: podnet
    method_type: multi_steps
    # eval_metric Choises: acc, recall
    eval_metric: acc

    # Backbone Choises: resnet18, resnet18_cbam, cosine_resnet18, 
    # resnet32, cosine_resnet32, resnet34, cosine_resnet34, resnet50
    backbone: cosine_resnet18
    pretrained: true
    save_models: true # if true, programm will save model's weights during incremental train

    ######### Exampler Hyperparameters #########
    memory_size: 200
    fixed_memory: false
    sampling_method: herding # herding, random, closest_to_mean

    apply_nme: true

    ######### Task Settings, unimportant in Joint #########
    # for some datasets(e.g. MedMNist), this will be ignored
    split_dataset: true

    note: seed1_new

######### Method's Hyperparameters #########
special:
    incre_type: cil
    lambda_c_base: 5
    lambda_f_base: 1
    nb_proxy: 10

######### Experiment Settings for Datasets #########
options:
    # experiment settings for cifar100
    mymedmnist: 
        cosine_resnet18:
            img_size: 224

            layer_names: ['layer1', 'layer2', 'layer3', 'layer3']
            
            epochs: 160 # 160
            batch_size: 64
            num_workers: 8

            opt_type: sgd
            lrate: 0.01
            weight_decay: 0.0005
            opt_mom: 0.9
            
            scheduler: cos
            
            epochs_finetune: 50
            lrate_finetune: 0.005

            

            
            
